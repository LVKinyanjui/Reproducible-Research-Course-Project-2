---
title: "Storm Data Analysis"
author: "LVK"
date: "6/9/2022"
output: html_document
---

# Exploring the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm data from 1950 to 2011

## Synopsis
This analysis will explore various effects of severe weather conditions in the United States over a sixty year period. This will be done in order to answer relevant questions about how to deal with such weather conditions that perhaps may find use in policy direction. Exploratory graphs will be produced and findings presented at the end.


## Data Processing
```{r}
library(tidyverse)
```


```{r Downloading Storm Data} 

fileUrl = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
filePath = "./data/stormdata"
dataFolder = "./data"

if(!dir.exists(dataFolder)) {dir.create(dataFolder)}
if(!file.exists(filePath)) {
      download.file(fileUrl, filePath)
}

download_date = Sys.Date()
```


``` {r, cache = TRUE}
t1 = Sys.time()
stormdata_df = read.csv("./data/stormdata")
t2 = Sys.time()
t2-t1

```

### Cleaning up the Dataset
Here we shall select only the columns of interest to reduce complexity.
``` {r}
min_storm_df = stormdata_df %>%
      select(BGN_DATE, TIME_ZONE, EVTYPE, WFO, F, MAG, STATE, STATE__, LENGTH, WIDTH)

#modifying time variable
min_storm_df$BGN_DATE = min_storm_df$BGN_DATE %>% 
                              as.Date(format = "%m/%d/%Y", 
                                      tz = min_storm_df$TIME_ZONE)
min_storm_df
```

Next we define the official events. These are 48 in number
``` {r} 
events_df = read.csv("./data/Eventslist.csv")
view(events_df)
existing_events = unique(stormdata_df$EVTYPE)

```

#### Heatmap
Let us inspect the event type EVTYPE variable
```{r}
set.seed(10)
x = sample(seq(1:length(end_date)), 1000, replace = FALSE)

partial_df = select(stormdata_df, EVTYPE)
partial_tbl = partial_df[x,] %>%
      table %>%
      as.data.frame

#Distance matrix and heatmap
distmatrix = dist(partial_tbl)

heatmap(as.matrix(distmatrix), margins = c(8,5))
```
I take the heatmap to mean that the unique occurences of the unique event types are relatively uniform; that is, there is only a few types that are very common. This variable needs to be cleaned up and reclassified into the 40 or so official types (down from the about 1000). This is a start. 

